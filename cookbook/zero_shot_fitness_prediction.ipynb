{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec38a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/Profluent-AI/E1.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cuda_capabilities = torch.cuda.get_device_capability(0)\n",
    "    if cuda_capabilities[0] >= 8:\n",
    "        print(\"CUDA 8.0 or higher detected; installing flash-attention\")\n",
    "        !pip install flash-attn --no-build-isolation\n",
    "    else:\n",
    "        print(\"CUDA capability lower than 8.0; will not be using flash attention\")\n",
    "else:\n",
    "    print(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc0fbd",
   "metadata": {},
   "source": [
    "### Scoring substitution variants of a protein\n",
    "\n",
    "In this notebook, we will use a DMS Assay (ID: AMIE_PSEAE_Wrenbeck_2017) from Protein Gym (https://proteingym.org/) containing substitution variants of a protein (Uniprot entry https://www.uniprot.org/uniprotkb/P11436/entry) to show zero-shot fitness prediction. We willcompute score of each variant using masked marginal method using the `E1` model directly in both single sequence and retrieval augmented mode and measure correlation with experimental fitness values. For an explanation of the masked marginal method, please refer to this [paper](https://proceedings.neurips.cc/paper/2021/file/f51338d736f95dd42427296047067694-Supplemental.pdf). In short, we replace each mutated position with mask token and compute the log probability of the actual residue at that position. We then compute the score of the single substitution mutant as the difference in log probability between the mutant and the wildtype. The score for multiple substitutions is computed as the sum of the scores of the individual single substitutions.\n",
    "\n",
    "While we do similar scoring as basic notebook, we will use the `E1Scorer` utility to compute scores, which makes things much easier and faster by auto-batching and KV caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99269189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "wildtype_sequence = (\n",
    "    \"MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMKQGLPGMDLVVFPEYSLQGIMYDPAEMMETAVAI\"\n",
    "    \"PGEETEIFSRACRKANVWGVFSLTGERHEEHPRKAPYNTLVLIDNNGEIVQKYRKIIPWCPIEGWYPGGQTYVSEGPKG\"\n",
    "    \"MKISLIICDDGNYPEIWRDCAMKGAELIVRCQGYMYPAKDQQVMMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIG\"\n",
    "    \"FDGRTLGECGEEEMGIQYAQLSLSQIRDARANDQSQNHLFKILHRGYSGLQASGDGDRGLAECPFEFYRTWVTDAEKARE\"\n",
    "    \"NVERLTRSTTGVAQCPVGRLPYEGLEKEA\"\n",
    ")\n",
    "\n",
    "assay_data = pl.read_csv(\"https://huggingface.co/datasets/Profluent-Bio/AMIE_PSEAE_Wrenbeck_2017_example/resolve/main/AMIE_PSEAE_Wrenbeck_2017.csv\")\n",
    "print(assay_data.head())\n",
    "\n",
    "mutated_sequences = assay_data[\"mutated_sequence\"].to_list()\n",
    "mutated_sequence_ids = assay_data[\"mutant\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from E1 import dist\n",
    "from E1.modeling import E1ForMaskedLM\n",
    "from E1.scorer import E1Scorer, EncoderScoreMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Profluent-Bio/E1-300m\"\n",
    "max_batch_tokens = 4096\n",
    "# Also available: EncoderScoreMethod.WILDTYPE_MARGINAL which is generally faster but less accurate\n",
    "scoring_method = EncoderScoreMethod.MASKED_MARGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = E1ForMaskedLM.from_pretrained(model_name, dtype=torch.float).to(dist.get_device()).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7992ded",
   "metadata": {},
   "source": [
    "We initialize the scorer with the model and the scoring method (either WILDTYPE_MARGINAL or MASKED_MARGINAL) and a max batch tokens limit (set this to lower if you encounter CUDA OOM errors). Then, we call the `score` method with the wildtype sequence and the list of mutated sequences. Note, that the `score` method returns a list of dictionaries with the score for each mutated sequence (but it may not be the same order as the sequences list passed in the arguments). Use the `id` field in the returned dictionaries to match the score with the corresponding mutated sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = E1Scorer(model, method=scoring_method, max_batch_tokens=max_batch_tokens)\n",
    "scores = scorer.score(\n",
    "    parent_sequence=wildtype_sequence,  # parent sequence\n",
    "    sequences=mutated_sequences,  # list of mutated sequences we want to score (substitutions only)\n",
    "    sequence_ids=mutated_sequence_ids,  # list of sequence ids for each mutated sequence\n",
    ")\n",
    "print(scores[:10])\n",
    "scores = pl.from_dicts(scores)\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a01063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "scores = scores.join(assay_data, left_on=\"id\", right_on=\"mutant\", how=\"left\")\n",
    "print(spearmanr(scores[\"score\"], scores[\"DMS_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25841877",
   "metadata": {},
   "source": [
    "### Scoring using Retrieval Augmented Mode\n",
    "\n",
    "In this section, we will an MSA to sample homolog sequences for the wildtype sequence used above and pass them to the model as part of the context. \n",
    "\n",
    "Note: You will very likely encounter CUDA OOM error if using T4 gpu on colab. We recommend using A100 or L40 gpu when working in retrieval augmented mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571223c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/datasets/Profluent-Bio/AMIE_PSEAE_Wrenbeck_2017_example/resolve/main/msa.a3m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958b549",
   "metadata": {},
   "source": [
    "We generally find that ensembling scores over multiple context sequences sampled from the same protein family helps improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from E1.msa_sampling import ContextSpecification, sample_multiple_contexts\n",
    "\n",
    "msa_path = \"msa.a3m\"\n",
    "context_token_lengths = [7168, 14336, 21504]\n",
    "max_query_similarities = [1.0, 0.95, 0.9, 0.7, 0.5]\n",
    "\n",
    "context_specs = []\n",
    "for max_num_tokens in context_token_lengths:\n",
    "    for max_query_similarity in max_query_similarities:\n",
    "        context_specs.append(\n",
    "            ContextSpecification(\n",
    "                # maximum number of sequences that can be sampled from the MSA (should be <= 511)\n",
    "                max_num_samples=511,\n",
    "                # maximum number of concatenated tokens in the context sequences\n",
    "                max_token_length=max_num_tokens,\n",
    "                # maximum similarity between the query and the context sequences\n",
    "                max_query_similarity=max_query_similarity,\n",
    "                # minimum similarity between the query and the context sequences\n",
    "                min_query_similarity=0.0,\n",
    "                # minimum similarity between the two sequences for them to be considered neighbors during MSA Sampling\n",
    "                neighbor_similarity_lower_bound=0.8,\n",
    "            )\n",
    "        )\n",
    "\n",
    "context_seqs, _ = sample_multiple_contexts(msa_path=msa_path, context_specifications=context_specs, seed=0)\n",
    "\n",
    "context_seqs_dict = {f\"context_{i}\": seq for i, seq in enumerate(context_seqs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = E1Scorer(model, method=EncoderScoreMethod.MASKED_MARGINAL, max_batch_tokens=max_batch_tokens)\n",
    "scores = scorer.score(\n",
    "    parent_sequence=wildtype_sequence,  # parent sequence\n",
    "    sequences=mutated_sequences,  # list of mutated sequences we want to score (substitutions only)\n",
    "    sequence_ids=mutated_sequence_ids,  # list of sequence ids for each mutated sequence\n",
    "    context_seqs=context_seqs_dict,  # dictionary of context sequences\n",
    "    # we ensemble scores over multiple context sequences by taking mean; set to \"none\" to return\n",
    "    # scores with respect to each context sequence individually\n",
    "    context_reduction=\"mean\",\n",
    ")\n",
    "print(scores[:10])\n",
    "scores = pl.from_dicts(scores)\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dab331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "scores = scores.join(assay_data, left_on=\"id\", right_on=\"mutant\", how=\"left\")\n",
    "print(spearmanr(scores[\"score\"], scores[\"DMS_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0bc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
