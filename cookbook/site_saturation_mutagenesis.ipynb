{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48283dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/Profluent-AI/E1.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeaf101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cuda_capabilities = torch.cuda.get_device_capability(0)\n",
    "    if cuda_capabilities[0] >= 8:\n",
    "        print(\"CUDA 8.0 or higher detected; installing flash-attention\")\n",
    "        !pip install flash-attn --no-build-isolation\n",
    "    else:\n",
    "        print(\"CUDA capability lower than 8.0; will not be using flash attention\")\n",
    "else:\n",
    "    print(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb5e76",
   "metadata": {},
   "source": [
    "### In-silico scanning single site saturation mutagenesis\n",
    "\n",
    "In this notebook, we use E1 model to score every single site mutant of the wildtype protein from the AMIE_PSEAE_Wrenbeck_2017 dataset (Uniprot entry https://www.uniprot.org/uniprotkb/P11436/entry) and return the score for each mutation ordered by descending score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef02b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from E1 import dist\n",
    "from E1.modeling import E1ForMaskedLM\n",
    "from E1.msa_sampling import ContextSpecification, sample_multiple_contexts\n",
    "from E1.scorer import E1Scorer, EncoderScoreMethod\n",
    "\n",
    "\n",
    "def ssm(\n",
    "    parent_sequence: str,\n",
    "    msa_path: str | None = None,\n",
    "    model_name: str = \"Profluent-Bio/E1-300m\",\n",
    "    scoring_method: EncoderScoreMethod = EncoderScoreMethod.MASKED_MARGINAL,\n",
    "    max_batch_tokens: int = 4096,\n",
    "    singleseq_mode: bool = False,\n",
    "):\n",
    "    model = E1ForMaskedLM.from_pretrained(model_name, dtype=torch.float).to(dist.get_device()).eval()\n",
    "    scorer = E1Scorer(model, method=scoring_method, max_batch_tokens=max_batch_tokens)\n",
    "\n",
    "    if not singleseq_mode:\n",
    "        assert msa_path is not None, \"MSA path is required for retrieval augmented mode\"\n",
    "        context_token_lengths = [7168, 15360, 23552]\n",
    "        max_query_similarities = [1.0, 0.95, 0.9, 0.7, 0.5]\n",
    "\n",
    "        context_specs = []\n",
    "        for max_num_tokens in context_token_lengths:\n",
    "            for max_query_similarity in max_query_similarities:\n",
    "                context_specs.append(\n",
    "                    ContextSpecification(\n",
    "                        max_num_samples=512,\n",
    "                        max_token_length=max_num_tokens,\n",
    "                        max_query_similarity=max_query_similarity,\n",
    "                        min_query_similarity=0.0,\n",
    "                        neighbor_similarity_lower_bound=0.8,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        context_seqs, _ = sample_multiple_contexts(msa_path=msa_path, context_specifications=context_specs, seed=42)\n",
    "\n",
    "        context_seqs_dict = {f\"context_{i}\": seq for i, seq in enumerate(context_seqs)}\n",
    "    else:\n",
    "        context_seqs_dict = None\n",
    "\n",
    "    positions_masked = list(range(0, len(parent_sequence)))\n",
    "    position_scores, _ = scorer.get_position_scores(\n",
    "        parent_sequence=parent_sequence,\n",
    "        mutation_positions=positions_masked,\n",
    "        context_seqs=context_seqs_dict,\n",
    "        context_reduction=\"mean\",\n",
    "    )\n",
    "    assert position_scores.shape == (1, len(parent_sequence), len(scorer.vocab))\n",
    "\n",
    "    aa_string = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    aa_ids = [scorer.vocab[aa] for aa in aa_string]\n",
    "    scores_heatmap = position_scores[0, :, aa_ids].cpu().numpy()\n",
    "\n",
    "    mutant_scores = []\n",
    "    for i in range(len(parent_sequence)):\n",
    "        for j, aa in enumerate(aa_string):\n",
    "            if aa == parent_sequence[i]:\n",
    "                continue\n",
    "            mutant_scores.append((i, aa, scores_heatmap[i, j].item()))\n",
    "\n",
    "    mutant_scores = pd.DataFrame(mutant_scores, columns=[\"position\", \"mutant\", \"score\"]).sort_values(\n",
    "        by=\"score\", ascending=False\n",
    "    )\n",
    "\n",
    "    return mutant_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d54d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_sequence = (\n",
    "    \"MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMKQGLPGMDLVVFPEYSLQGIMYDPAEMMETAVAIPGEETEIFSRACRKANV\"\n",
    "    \"WGVFSLTGERHEEHPRKAPYNTLVLIDNNGEIVQKYRKIIPWCPIEGWYPGGQTYVSEGPKGMKISLIICDDGNYPEIWRDCAMKGAELIVRCQGY\"\n",
    "    \"MYPAKDQQVMMAKAMAWANNCYVAVANAAGFDGVYSYFGHSAIIGFDGRTLGECGEEEMGIQYAQLSLSQIRDARANDQSQNHLFKILHRGYSGLQA\"\n",
    "    \"SGDGDRGLAECPFEFYRTWVTDAEKARENVERLTRSTTGVAQCPVGRLPYEGLEKEA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e14e3",
   "metadata": {},
   "source": [
    "#### Scoring in Single Sequence Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a pandas dataframe containing all single mutant scores with columns position, mutant, and score\n",
    "mutant_scores = ssm(parent_sequence, model_name=\"Profluent-Bio/E1-300m\", singleseq_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e57bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out top-96 mutants. The position is 0-indexed.\n",
    "mutant_scores.head(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find score for specific mutant like R2H (1-indexed) or R1H (0-indexed)\n",
    "mutant_scores[(mutant_scores[\"position\"] == 1) & (mutant_scores[\"mutant\"] == \"H\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4bc5a",
   "metadata": {},
   "source": [
    "#### Scoring in Retrieval Augmented Mode\n",
    "\n",
    "Note: You will very likely encounter CUDA OOM error if using T4 gpu on colab. We recommend using A100 or L40 gpu when working in retrieval augmented mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba4fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/datasets/Profluent-Bio/AMIE_PSEAE_Wrenbeck_2017_example/resolve/main/msa.a3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ece3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a pandas dataframe containing all single mutant scores with columns position, mutant, and score\n",
    "# Use MSA to provide context sequences. Takes about 2-3 min on A100 gpu.\n",
    "mutant_scores = ssm(\n",
    "    parent_sequence, \n",
    "    model_name=\"Profluent-Bio/E1-300m\", \n",
    "    singleseq_mode=False, \n",
    "    msa_path=\"msa.a3m\",\n",
    "    scoring_method=EncoderScoreMethod.WILDTYPE_MARGINAL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96939e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out top-96 mutants. The position is 0-indexed.\n",
    "mutant_scores.head(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9846c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find score for specific mutant like R2H (1-indexed) or R1H (0-indexed)\n",
    "mutant_scores[(mutant_scores[\"position\"] == 1) & (mutant_scores[\"mutant\"] == \"H\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76b01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
